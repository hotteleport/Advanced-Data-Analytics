{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Optimal Variable Selection\n",
    "Classification Dataset\n",
    "We used SelectKBest with ANOVA F-score and a correlation matrix to evaluate variable importance. Features such as total_order_kcal, total_web_sessions, and total_web_sessions_since_last_order ranked highest. Low-performing features (e.g., signup_promo, pet_allergen_list) were removed. A model trained on the reduced feature set performed nearly identically to the full model, confirming their redundancy.\n",
    "\n",
    "Regression Dataset\n",
    "We applied SelectKBest (f_regression), correlation matrix, and VIF (Variance Inflation Factor) to assess the influence of each variable. Features like distance, CO2_emissions, and engine_efficiency were highly predictive. VIF analysis revealed multicollinearity in a few variables (e.g., CO2_emissions), and removing them had minimal impact on model performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Feature Generation & Interaction Features\n",
    "Classification Dataset\n",
    "Three engineered features were added:\n",
    "\n",
    "avg_minutes_per_session – a ratio of time spent per session\n",
    "\n",
    "total_engagement – combined past and recent session activity\n",
    "\n",
    "user_cluster – KMeans-based user segmentation using behavior\n",
    "\n",
    "After evaluating importance with SelectKBest and RandomForestClassifier, the new features ranked in the top 5, confirming added predictive value.\n",
    "\n",
    "Regression Dataset\n",
    "We created several new features:\n",
    "\n",
    "fuel_per_distance – ratio of fuel to distance traveled\n",
    "\n",
    "co2_per_fuel – efficiency indicator\n",
    "\n",
    "total_energy_output – additive metric combining fuel and CO2\n",
    "\n",
    "ship_profile_cluster – clustering ships based on distance, weather, and engine efficiency\n",
    "\n",
    "Both statistical (SelectKBest) and model-based (RandomForestRegressor) importance metrics confirmed that these features contributed meaningfully to model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Evaluation\n",
    "Descriptive Analysis\n",
    "Distributions and variance of the engineered datasets were compared against original versions using describe(), .var(), and correlation matrices. The values remained consistent with realistic ship/pet behavior and purchasing patterns.\n",
    "\n",
    "Model Performance\n",
    "Model comparisons (with and without engineered features) were conducted for both tasks. Feature-engineered models showed improved:\n",
    "\n",
    "Classification: Accuracy, Precision, F1-Score\n",
    "\n",
    "Regression: R², MAE, RMSE\n",
    "\n",
    "The improvements were visualized using side-by-side bar charts and confusion matrices.\n",
    "\n",
    "Conclusion:\n",
    "Feature engineering significantly enhanced both datasets without compromising realism. The newly created features improved model interpretability and performance. We validated all steps using multiple tools (SelectKBest, correlation matrix, VIF, and Random Forest), ensuring balanced and explainable optimizations."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
